---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Welcome to my homepage! I am currently a research engineer at [Beijing Institute for General Artificial Intelligence](https://eng.bigai.ai/). My current research interests include: Embodied AI, Video Understanding and Robotics. Previously I worked on Bioinformatics and Graph Representation learning. In my leisure time, I am also intrested in Quantitative Trading.

Education
======
2016.9-2020.6, Bachelor in Computer Science, Peking University\
2020.9-2023.6, Master in Intelligence Science and Technology, Peking University


Experiences
======
2022.7-2022.12, Research Intern, Microsoft Research Aisa.\
We won the **second place** in the NeurIPS 2022 OGB-LSC challenge, which is a competition of link prediction on huge knowledge graphs. Our technical report can be found [here](https://ogb.stanford.edu/paper/neurips2022/wikikg90mv2_DNAKG.pdf).



Publications
======
**Yue Fan**, Xiaojian Ma, Rongpeng Su, Jun Guo, Rujie Wu, Xi Chen, Qing Li. Embodied VideoAgent: Persistent Memory from Egocentric Videos and Embodied Sensors Enables Dynamic Scene Understanding. ICCV 2025. [[pdf](https://www.arxiv.org/pdf/2501.00358)]\
We introduces Embodied VideoAgent, an LLM-based system that builds dynamic 3D scene memory from egocentric videos and embodied sensors, achieving state-of-the-art performance in reasoning and planning tasks.



Zhi Gao, Bofei Zhang, Pengxiang Li, Xiaojian Ma, Tao Yuan, **Yue Fan**, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li. Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage. ICLR 2025 Spotlight. [[pdf](https://arxiv.org/pdf/2412.15606)]\
We proposes T3-Agent, a multi-modal agent tuned with the MM-Traj dataset for better tool-usage reasoning, boosting VLM performance by 20% on benchmarks.

**Yue Fan**, Xiaojian Ma, Rujie Wu, Yuntao Du, Jiaqi Li, Zhi Gao, Qing Li. VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding. ECCV 2024. [[pdf](https://arxiv.org/pdf/2403.11481.pdf)]\
We build VideoAgent that understands long videos and achieves the performance close to Gemini 1.5 Pro. Details can be found [here](https://videoagent.github.io).

Jun Guo, Xiaojian Ma, **Yue Fan**, Huaping Liu, Qing Li. Semantic Gaussians: Open-Vocabulary Scene Understanding with 3D Gaussian Splatting. arxiv 2024. [[pdf](https://arxiv.org/pdf/2403.15624.pdf)]\
This work reconstructs the 3D scenes and perserves the semantic information using Gaussian splatting.


Tianxu Wang, **Yue Fan**, Xiuli Ma. Attention Based Models for Cell Type Classification on Single-Cell RNA-Seq Data. ECAI 2023. [[pdf](https://ebooks.iospress.nl/volumearticle/64489)]\
We build two kinds of attention-based model to predict the types of the cells. We found the attention weights to be a good interpretation for cell-type classification. **This paper is awarded as the outstanding paper for AI in socal good.**

**Yue Fan**, Xiuli Ma. Multi-vector embedding on networks with taxonomies. IJCAI 2022. [[pdf](https://www.ijcai.org/proceedings/2022/0408.pdf)]\
We build a novel graph embedding method that adaptively learns multiple representation vectors for each node in a hyperbolic space.


**Yue Fan**, Xiuli Ma. Gene regulatory network inference using 3D convolutional neural network. AAAI 2021. [[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/16082)]\
A 3D convolutional neural network is built and serves a good gene regulatory network predictor.

Junshan Wang, Zhicong Lu, Guojia Song, **Yue Fan**, Lun Du, Wei Lin. Tag2vec: Learning tag representations in tag networks. WWW 2019. [[pdf](https://arxiv.org/pdf/1905.03041.pdf)]\
Tag2Vec learns the embedding of both the nodes and their tags in a hyperbolic space.



<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=TIeYjEODY7oKR2GFoYcES7YEEd-MxYlAZa5vnTU6D5M&cl=ffffff&w=a"></script>
